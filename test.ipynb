{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.aivene import Aivene\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clients with API keys\n",
    "client = OpenAI(api_key=\"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\")\n",
    "aivene_client = Aivene(api_key='zpka_3de3b52b153f4f19a5c18f48dd76abbe_2a5f1d20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant ID: asst_nsReF2BmbDdOHCrxmtNmQ8We\n",
      "Thread: Thread(id='thread_juWUVpLZGT6c1Sn0xlcSQ5d8', created_at=1705426669, metadata={}, object='thread')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Ongoing conversation loop\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py:1191\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py:1234\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1232\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Step 1: Upgrade to Python SDK v1.2 with pip install --upgrade openai\n",
    "# Step 2: Install Tavily Python SDK with pip install tavily-python\n",
    "# Step 3: Build an OpenAI assistant with Python SDK documentation - https://platform.openai.com/docs/assistants/overview\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "assistant_prompt_instruction = \"\"\"You are a finance expert. \n",
    "Your goal is to provide answers based on information from the internet. \n",
    "You must use the provided Tavily search API function to find relevant online information. \n",
    "You should never use your own knowledge to answer questions.\n",
    "Please include relevant url sources in the end of your answers.\n",
    "\"\"\"\n",
    "\n",
    "# Function to perform a Tavily search\n",
    "def aivene_search(query):\n",
    "    search_result = aivene_client.search_from_input(user_input=query)\n",
    "    return search_result\n",
    "\n",
    "# Function to wait for a run to complete\n",
    "def wait_for_run_completion(thread_id, run_id):\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n",
    "        print(f\"Current run status: {run.status}\")\n",
    "        if run.status in ['completed', 'failed', 'requires_action']:\n",
    "            return run\n",
    "\n",
    "# Function to handle tool output submission\n",
    "def submit_tool_outputs(thread_id, run_id, tools_to_call):\n",
    "    tool_output_array = []\n",
    "    for tool in tools_to_call:\n",
    "        output = None\n",
    "        tool_call_id = tool.id\n",
    "        function_name = tool.function.name\n",
    "        function_args = tool.function.arguments\n",
    "\n",
    "        if function_name == \"aivene_search\":\n",
    "            output = aivene_search(query=json.loads(function_args)[\"query\"])\n",
    "\n",
    "        if output:\n",
    "            tool_output_array.append({\"tool_call_id\": tool_call_id, \"output\": output})\n",
    "\n",
    "    return client.beta.threads.runs.submit_tool_outputs(\n",
    "        thread_id=thread_id,\n",
    "        run_id=run_id,\n",
    "        tool_outputs=tool_output_array\n",
    "    )\n",
    "\n",
    "# Function to print messages from a thread\n",
    "def print_messages_from_thread(thread_id):\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    for msg in messages:\n",
    "        print(f\"{msg.role}: {msg.content[0].text.value}\")\n",
    "\n",
    "# Create an assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=assistant_prompt_instruction,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    tools=[{\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"aivene_search\",\n",
    "            \"description\": \"Get information on recent events from the web.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\", \"description\": \"The search query to use. For example: 'Latest news on Nvidia stock performance'\"},\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    }]\n",
    ")\n",
    "assistant_id = assistant.id\n",
    "print(f\"Assistant ID: {assistant_id}\")\n",
    "\n",
    "# Create a thread\n",
    "thread = client.beta.threads.create()\n",
    "print(f\"Thread: {thread}\")\n",
    "\n",
    "# Ongoing conversation loop\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Create a message\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=user_input,\n",
    "    )\n",
    "\n",
    "    # Create a run\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant_id,\n",
    "    )\n",
    "    print(f\"Run ID: {run.id}\")\n",
    "\n",
    "    # Wait for run to complete\n",
    "    run = wait_for_run_completion(thread.id, run.id)\n",
    "\n",
    "    if run.status == 'failed':\n",
    "        print(run.error)\n",
    "        continue\n",
    "    elif run.status == 'requires_action':\n",
    "        run = submit_tool_outputs(thread.id, run.id, run.required_action.submit_tool_outputs.tool_calls)\n",
    "        run = wait_for_run_completion(thread.id, run.id)\n",
    "\n",
    "    # Print messages from the thread\n",
    "    print_messages_from_thread(thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
